"""
å…¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ¼ã‚¸ã—ã¦å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
"""
import json
import os
from collections import Counter

DATA_DIR = "/Users/yuki/workspace/qwen-jp/data"
OUTPUT_PATH = f"{DATA_DIR}/eliochat_final.jsonl"

# ãƒãƒ¼ã‚¸å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ–°è¦ç”Ÿæˆåˆ†ã®ã¿ï¼‰
TARGET_FILES = [
    "logic_math.jsonl",
    "reasoning.jsonl",
    "tool_calling.jsonl",
    "japan_knowledge.jsonl",
    "japanese_cultural_logic.jsonl",
    "japanese_expressions.jsonl",
    "identity_creator.jsonl",
    "current_events.jsonl",
    "witty_qa.jsonl",
    "witty_companion.jsonl",
    "japanese_commonsense.jsonl",
    "bias_neutralization.jsonl",
    "philosophy_mentor.jsonl",
    "safety_deflection.jsonl",
    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ç”Ÿæˆä¸­ã®ã‚‚ã®ã‚‚å«ã‚ã‚‹ï¼ˆç©ºã§ã‚‚OKï¼‰
    "offline_mode.jsonl",
    "conversation_hooks.jsonl",
    "reasoning_40.jsonl",
    "top100_questions.jsonl",
]

def load_jsonl(filepath):
    """JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    items = []
    if not os.path.exists(filepath):
        return items
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    items.append(json.loads(line))
    except Exception as e:
        print(f"Error loading {filepath}: {e}")
    return items

def validate_item(item):
    """ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’æ¤œè¨¼"""
    if "messages" not in item:
        return False
    messages = item["messages"]
    if not isinstance(messages, list) or len(messages) < 2:
        return False
    # system, user, assistant ã®é †åºç¢ºèª
    roles = [m.get("role") for m in messages]
    if "user" not in roles or "assistant" not in roles:
        return False
    return True

def main():
    print("=" * 60)
    print("ElioChatå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸")
    print("=" * 60)

    all_data = []
    category_counts = Counter()
    file_counts = {}

    for filename in TARGET_FILES:
        filepath = os.path.join(DATA_DIR, filename)
        items = load_jsonl(filepath)

        valid_items = [item for item in items if validate_item(item)]
        invalid_count = len(items) - len(valid_items)

        if invalid_count > 0:
            print(f"  è­¦å‘Š: {filename} - {invalid_count}ä»¶ã®ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—")

        file_counts[filename] = len(valid_items)
        all_data.extend(valid_items)

        # ã‚«ãƒ†ã‚´ãƒªé›†è¨ˆ
        for item in valid_items:
            cat = item.get("metadata", {}).get("category", "unknown")
            category_counts[cat] += 1

    print("\nğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ä»¶æ•°:")
    for filename, count in sorted(file_counts.items(), key=lambda x: -x[1]):
        if count > 0:
            print(f"  {filename}: {count}ä»¶")

    print(f"\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥ä»¶æ•°:")
    for cat, count in category_counts.most_common(20):
        print(f"  {cat}: {count}ä»¶")

    # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ™ãƒ¼ã‚¹ï¼‰
    seen_queries = set()
    unique_data = []
    duplicate_count = 0

    for item in all_data:
        user_msg = ""
        for msg in item["messages"]:
            if msg["role"] == "user":
                user_msg = msg["content"][:200]  # æœ€åˆã®200æ–‡å­—
                break

        if user_msg and user_msg not in seen_queries:
            seen_queries.add(user_msg)
            unique_data.append(item)
        else:
            duplicate_count += 1

    print(f"\nğŸ” é‡è¤‡ãƒã‚§ãƒƒã‚¯:")
    print(f"  å…ƒãƒ‡ãƒ¼ã‚¿: {len(all_data)}ä»¶")
    print(f"  é‡è¤‡: {duplicate_count}ä»¶")
    print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯: {len(unique_data)}ä»¶")

    # ä¿å­˜
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        for item in unique_data:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

    print(f"\nâœ… ä¿å­˜å®Œäº†: {OUTPUT_PATH}")
    print(f"   ç·ä»¶æ•°: {len(unique_data)}ä»¶")

    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ğŸ“ˆ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"ç·å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(unique_data)}ä»¶")

    # ã‚«ãƒ†ã‚´ãƒªå¤§åˆ†é¡
    major_categories = {
        "è«–ç†ãƒ»æ•°å­¦": ["logic", "math", "calculation"],
        "æ¨è«–ãƒ»æ€è€ƒ": ["reasoning", "fermi", "analysis"],
        "æ—¥æœ¬èªãƒ»æ–‡åŒ–": ["japan", "cultural", "commonsense", "expression"],
        "ãƒ„ãƒ¼ãƒ«ä½¿ç”¨": ["tool"],
        "ã‚¦ã‚£ãƒƒãƒˆãƒ»ãƒ¦ãƒ¼ãƒ¢ã‚¢": ["witty", "companion", "philosophy"],
        "å®‰å…¨æ€§ãƒ»ãƒã‚¤ã‚¢ã‚¹": ["safety", "bias", "deflection"],
        "ãã®ä»–": []
    }

    major_counts = Counter()
    for cat, count in category_counts.items():
        matched = False
        for major, keywords in major_categories.items():
            if any(kw in cat.lower() for kw in keywords):
                major_counts[major] += count
                matched = True
                break
        if not matched:
            major_counts["ãã®ä»–"] += count

    print("\nå¤§åˆ†é¡:")
    for major, count in major_counts.most_common():
        pct = count / len(unique_data) * 100
        print(f"  {major}: {count}ä»¶ ({pct:.1f}%)")

if __name__ == "__main__":
    main()
